{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "class CustomCartPoleEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.reward_function = self.LLMRewardFunction\n",
    "\n",
    "    def step(self, action):\n",
    "        observation, _, terminated, truncated, info = self.env.step(action)\n",
    "        reward = self.reward_function(observation, action)\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "   #  def angle_based_reward(self, observation, action):\n",
    "   #      _, _, angle, _ = observation\n",
    "   #      return np.cos(angle)  # Higher reward when angle is closer to 0 (vertical)\n",
    "\n",
    "   #  def combined_reward(self, observation, action):\n",
    "   #      x, _, angle, _ = observation\n",
    "   #      return np.cos(angle) + (1 - abs(x) / 2.4)  # Combine angle and position rewards\n",
    "    \n",
    "    def LLMRewardFunction(self, function_string):\n",
    "        local_namespace = {}\n",
    "        # Execute the function string in the local namespace\n",
    "        exec(function_string, globals(), local_namespace)\n",
    "        \n",
    "        # Find the function in the local namespace\n",
    "        new_function = None\n",
    "        for item in local_namespace.values():\n",
    "            if callable(item):\n",
    "                new_function = item\n",
    "                break\n",
    "        \n",
    "        if new_function is None:\n",
    "            raise ValueError(\"No function found in the provided string\")\n",
    "        \n",
    "        # Set the new function as the reward function\n",
    "        self.set_reward_function(new_function)\n",
    "\n",
    "    def set_reward_function(self, reward_function):\n",
    "        self.reward_function = reward_function\n",
    "\n",
    "def simple_angle_policy(observation):\n",
    "    _, _, angle, _ = observation\n",
    "    return 1 if angle > 0 else 0\n",
    "\n",
    "# def position_and_angle_policy(observation):\n",
    "#     x, _, angle, _ = observation\n",
    "#     if abs(x) > 1.0:  # If cart is far from center\n",
    "#         return 0 if x > 0 else 1  # Move towards center\n",
    "#     else:\n",
    "#         return 1 if angle > 0 else 0  # Otherwise, balance the pole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def LLMOutput(observation, action):\n",
      "    x, _, angle, _ = observation\n",
      "    \n",
      "    reward = 0\n",
      "    \n",
      "    # Reward for keeping the pole upright\n",
      "    angle_reward = 1 - abs(angle) / 0.2  # Normalize angle to [0, 1]\n",
      "    reward += max(0, angle_reward)\n",
      "    \n",
      "    # Penalty for moving too far from the center\n",
      "    position_penalty = -abs(x) / 2.4  # Normalize position to [-1, 0]\n",
      "    reward += max(-1, position_penalty)\n",
      "    \n",
      "    # Small reward for taking action (to encourage exploration)\n",
      "    reward += 0.1 if action != 0 else 0\n",
      "    \n",
      "    # Bonus for keeping the pole very close to vertical\n",
      "    if abs(angle) < 0.05:\n",
      "        reward += 0.5\n",
      "    \n",
      "    # Penalty for extreme angles\n",
      "    if abs(angle) > 0.3:\n",
      "        reward -= 1\n",
      "    \n",
      "    return reward\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "env = CustomCartPoleEnv(env)\n",
    "\n",
    "#API Query\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "generatedRewardFunction = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\"\n",
    "\n",
    "         , \"content\": \"\"\"You are a python code outputter. I want your output to only be python code and just be one function. No other text with it the output. \n",
    "         This function will be a reward function, named LLMOutput(), for a RL environment that follows the description below. \n",
    "         The inputs are observation and action in that order, the input observation can be broken down as follows: x, _, angle,_ = observation :\n",
    "         \n",
    "         This environment is a pole balanced on a cart that can move from left to right, \n",
    "         the idea is to keep the pole as upright as possible by moving the cart either left or right, \n",
    "         the information you have available to you is the position(x) and the angle(angle).\"\"\"}\n",
    "    ]\n",
    ")\n",
    "print(generatedRewardFunction.content[0].text)\n",
    "\n",
    "\n",
    "# generatedRewardFunction = \"\"\"def LLMOutput(observation, action):\n",
    "#    x, _, angle, _ = observation\n",
    "#    reward = 1.0 - abs(angle) - 0.5 * abs(x)\n",
    "#    if abs(angle) > 0.2 or abs(x) > 2.4:\n",
    "#        reward -= 10\n",
    "#    return reward\n",
    "# \"\"\"#API call to Claude\n",
    "\n",
    "# Set initial policy and reward function\n",
    "env.LLMRewardFunction(generatedRewardFunction.content[0].text)\n",
    "current_policy = simple_angle_policy  # Set the policy \n",
    "\n",
    "\n",
    "# Main loop\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    action = current_policy(observation)\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
